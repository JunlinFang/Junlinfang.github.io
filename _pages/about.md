---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}
<span class='anchor' id='about-me'></span>

# About Me

I am Junlin Fang (方俊麟), and I will be joining NTU's CCDS as a PhD student in Spring 2026, under the supervision of Prof. [Sean Du](https://d12306.github.io/index.html). Before that, I completed both my Master's and Bachelor's degrees at Southwest Jiaotong University, where I was advised by Prof. [Fengmao Lv](https://fengmaolv.github.io/online-cv/) and worked in close collaboration with Prof. [Wenya Wang](https://personal.ntu.edu.sg/wangwy/).

My research is primarily centered around exploring **Realiability**, **Security**, **Alignment**, and **Reasoning** within the context of Large Language Models and Multimodal Large Language Models.

# News

-  [9/25/2025] I receiee the PhD offer from Prof. [Sean Du](https://d12306.github.io/index.html)!!!
-  [7/6/2025] One paper is accepted to Multimedia 2025 as oral paper.
-  [1/21/2025] One paper is accepted to WWW 2025 as oral paper.
-  [7/25/2024] One paper is accepted to Multimedia 2024.
-  [2/25/2024] One paper is accepted to CIKM 2024 as oral paper.

# Publications

-  ``MultiMedia 2025`` Why is a Bird’s Caption a Good Demonstration? Towards Effective Multimodal In-Context Learning without Dedicated Data. **Junlin Fang**, Wenya Wang, Lingli Zhang, Fengmao Lv

- ``WWW 2025`` MSTI-Plus: Introducing Non-Sarcasm Reference Materials to Enhance Multimodal Sarcasm Target Identification. Fengmao Lv, Mengting Xiong, **Junlin Fang**, Lingli Zhang, Tianze Luo, Weichao Liange, Tianrui Li
  [\[PDF\](https://dl.acm.org/doi/10.1145/3696410.3714570) [\[Code\]](https://github.com/tiggers23/MSTI-Plus)

- ``MultiMedia 2024`` Sentiment-oriented Sarcasm Integration for Video Sentiment Analysis Enhancement with Sarcasm Assistance. **Junlin Fang**, Wenya Wang, Guosheng Lin, Fengmao Lv
  [\[PDF\]](https://dl.acm.org/doi/10.1145/3664647.3680703) [\[Code\]](https://github.com/tiggers23/PS2RI)

- ``CIKM 2024`` Progressive Multimodal Pivot Learning: Towards Semantic Discordance Understanding as Humans. **Junlin Fang**, Wenya Wang, Tianze Luo, Yanyong Huang, Fengmao Lv
  [\[PDF\]](https://dl.acm.org/doi/10.1145/3627673.3679524) [\[Code\]](https://github.com/tiggers23/PMPL)

- ``TKDE Under Major revision`` Modeling Deep Fusion of Intra- and Inter-Modal Incongruity for Multimodal Sarcasm Detection. Fengmao Lv, **Junlin Fang**, Guosheng Lin,Wenya Wang

- ``TOMM Under Major revision`` Rethinking the Effect of Unimodal Labels in Multimodal Sentiment Analysis. Lingli Zhang, Tianrui Li, Baiyu Lu, **Junlin Fang**, Desheng Zheng, Wei Zhou, Weide Liu, Fengmao Lv

# Educations
- *2026.01*, PhD, School of College of Computing and Data Science (CCDS), Nanyang Technological University, Singapore
- *2023.09 - 2025.12 (expected)*, Master, School of Computing and Artificial Intelligence, Southwest Jiaotong University, China. 
- *2019.09 - 2023.06*, Undergraduate, School of Computing and Artificial Intelligence, Southwest Jiaotong University, China.
